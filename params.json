{
  "name": "Nightcrawler",
  "tagline": "NightCrawler Web Scraper",
  "body": "# NightCrawler v1.2\r\n## NightCrawler Web Scraper\r\n\r\nNightCrawler is a tool developed on Python 2.7 that we can use as a footprinting tool against our own web pages.\r\n\r\nThe tool tries to fetch:\r\n\r\n- Enumerates and stores on a list [CHILD_LINKS] all the links finded from a ROOT node and under the same ROOT domain\r\n- A list [EMAIL_ACCOUNTS] with all the email accounts that the parser finds on the visited pages\r\n- A list [TEL_NUMS] with all the telephone numbers that the parser have found\r\n\r\nNightCrawler is Object Oriented (a Class), so you can reuse the code for make a better (more interesting?) program. The code at this point only follows links to web pages, not to binary files, but you can reuse the data that the \"crawler\" object generates through the Class attributes: CHILD_LINKS, BROKEN_LINKS, EMAIL_ACCOUNTS, TEL_NUMS\r\n\r\nAny improvement and comments to the code would be apreciate it.\r\n\r\nUsage:\r\n- You only need to change on line 18 of the code the base url parameter named ROOT (global variable):\r\n\r\nROOT = \"http://www.google.com/\"\r\n\r\nRequires:\r\n- Module Requests: HTTP for Humans (can be installed with the \"pip\" command) http://docs.python-requests.org/en/master/\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}