{
  "name": "Nightcrawler",
  "tagline": "NightCrawler Web Scraper",
  "body": "# NightCrawler v1.1\r\n## NightCrawler Web Scraper\r\n\r\nNightCrawler is a tool developed on Python 2.7 that we can use as a footprinting tool against our own web pages.\r\n\r\nThe tool tries to fetch:\r\n\r\n- Enumarates and saves on a list [CHILD_LINKS] all the pages linked from a ROOT node and under the same ROOT domain\r\n- A list [EMAIL_ACCOUNTS] with all the email accounts that the parser founds on the visited pages\r\n- A list [TEL_NUMS] with all the telephone numbers that the parser founds\r\n\r\nNightCrawler is Object Oriented (a Class), so you can reuse the code for make a better (more interesting?) program. The code at this point only follows links to web pages, not to binary files, but you can reuse the data that the \"crawler\" object generates through the Class attributes: CHILD_LINKS, BROKEN_LINKS, EMAIL_ACCOUNTS, TEL_NUMS\r\n\r\nAny improvement and comments to the code would be apreciate it.\r\n\r\nUsage:\r\n- You only need to change on line 18 the base url parameter named ROOT:\r\n\r\nROOT = \"http://www.google.com/\"\r\n\r\nRequires:\r\n- Module Requests: HTTP for Humans (can be installed with the \"pip\" command) http://docs.python-requests.org/en/master/\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}