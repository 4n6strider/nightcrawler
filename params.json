{
  "name": "Nightcrawler",
  "tagline": "NightCrawler Web Scrapper",
  "body": "# NightCrawler v1.0\r\n## NightCrawler Web Scrapper\r\n\r\nNightCrawler is a tool developed on Python 2.7 that we can use against our own web pages for footprinting.\r\n\r\nThe tool tries to fetch:\r\n\r\n- A list [CHILD_LINKS] with all the pages linked from a ROOT node\r\n- A list [EMAIL_ACCOUNTS] with all the email accounts that the parser founds on the visited pages\r\n- An a list [TEL_NUMS] with all the telephone numbers that the parser founds\r\n\r\nNightCrawler is Object Oriented (a Class), so you can reuse the code for make a better (more interesting?) program. The code at this point only follows links to web pages, not to binary files, but you can reuse the data that the \"crawler\" object generates through the Class fields: CHILD_LINKS, BROKEN_LINKS, EMAIL_ACCOUNTS, TEL_NUMS\r\n\r\nAny improvement and comments to the code would be apreciate it.\r\n\r\nUsage:\r\n- You only need to change on line 18 the base url parameter for ROOT variable:\r\n\r\nROOT = \"http://www.google.com/\"\r\n\r\nRequires:\r\n- Module Requests: HTTP for Humans (can be installed with the \"pip\" command) http://docs.python-requests.org/en/master/\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}